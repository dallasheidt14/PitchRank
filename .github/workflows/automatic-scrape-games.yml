name: Automatic Scrape Games

on:
  schedule:
    # Run every Monday at 12:01 AM UTC
    - cron: '1 0 * * 1'
  workflow_dispatch:
    # Allow manual triggers with same defaults
    inputs:
      concurrency:
        description: 'Number of concurrent scrapes'
        required: false
        type: string
        default: '30'

jobs:
  scrape-all-teams:
    runs-on: ubuntu-latest
    timeout-minutes: 360  # 6 hour timeout (GitHub Actions maximum)

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          # Additional dependencies for scraping
          pip install beautifulsoup4 lxml openpyxl pyarrow

      - name: Create directories
        run: |
          mkdir -p logs
          mkdir -p data/raw
          mkdir -p data/cache

      - name: Run Scrape and Import (All Teams)
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
          NEXT_PUBLIC_SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          PYTHONPATH: ${{ github.workspace }}
        run: |
          export PYTHONPATH="${PYTHONPATH}:${PWD}"
          python scripts/scrape_games.py --provider gotsport --auto-import --concurrency ${{ inputs.concurrency || '30' }}

      - name: Upload scraped data
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: scraped-games-${{ github.run_number }}
          path: data/raw/scraped_games_*.jsonl
          retention-days: 7
          if-no-files-found: ignore

      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: scrape-logs-${{ github.run_number }}
          path: |
            logs/*.log
          retention-days: 30
          if-no-files-found: ignore

      - name: Report results
        if: always()
        run: |
          echo "===================="
          echo "Automatic scrape completed"
          echo "===================="
          echo "Schedule: Every Monday at 12:01 AM UTC"
          echo "Mode: All eligible teams (not scraped in last 7 days)"
          echo "Concurrency: ${{ inputs.concurrency || '30' }}"
          echo "Check artifacts for scraped data and logs"
